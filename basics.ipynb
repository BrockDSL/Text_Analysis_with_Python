{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DSL_logo](dsl_logo.png)\n",
    "\n",
    "\n",
    "# Introduction to Text Analysis with Python\n",
    "\n",
    "Welcome to the Digital Scholarship Lab introduction to Text Analysis with Python class. In this class we'll learn the basics of text analysis:\n",
    "\n",
    "- parsing text\n",
    "- analyzing the text\n",
    "\n",
    "We'll use our own home made analysis tool first, then we'll use a python library called `TextBlob` to use some built-in analysis tools.\n",
    "\n",
    "This workshop assumes you've completed our Intro to Python [workshop](https://brockdsl.github.io/Intro_to_Python_Workshop/)\n",
    "\n",
    "We'll use the Zoom's chat feature to interact.\n",
    "\n",
    "Be sure to enable line numbers by looking for the 'gear' icon and checking the box in the 'Editor' panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EG. Scrabble!\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5d/Scrabble_game_in_progress.jpg\" width =500x>\n",
    "\n",
    "Scrabble is a popular game where players try to score points by spelling words and placing them on the game board. We'll use Scrabble scoring our our first attempt at text analysis. This will demonstart the basics of how Text Analysis works.\n",
    "\n",
    "The function below gives you the Scrabble scored of any word you give it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function will return the Scrabble score of a word\n",
    "\n",
    "def scrabble_score(word):\n",
    "    \n",
    "    #Dictionary of our scrabble scores\n",
    "    score_lookup = {\n",
    "        \"a\": 1,\n",
    "        \"b\": 3,\n",
    "        \"c\": 3,\n",
    "        \"d\": 2,\n",
    "        \"e\": 1,\n",
    "        \"f\": 4,\n",
    "        \"g\": 2,\n",
    "        \"h\": 4,\n",
    "        \"i\": 1,\n",
    "        \"j\": 8,\n",
    "        \"k\": 5,\n",
    "        \"l\": 1,\n",
    "        \"m\": 3,\n",
    "        \"n\": 1,\n",
    "        \"o\": 1,\n",
    "        \"p\": 3,\n",
    "        \"q\": 10,\n",
    "        \"r\": 1,\n",
    "        \"s\": 1,\n",
    "        \"t\": 1,\n",
    "        \"u\": 1,\n",
    "        \"v\": 4,\n",
    "        \"w\": 4,\n",
    "        \"x\": 8,\n",
    "        \"y\": 4,\n",
    "        \"z\": 10,\n",
    "        \"\\n\": 0, #just in case a new line character jumps in here\n",
    "        \" \":0 #normally single words don't have spaces but we'll put this here just in case\n",
    "        \n",
    "    }\n",
    "    \n",
    "    total_score = 0\n",
    "    \n",
    "    #We look up each letter in the scoring dictionary and add it to a running total\n",
    "    #to make our dictionary shorter we are just using lowercase letters so we need to\n",
    "    #change all of our input to lowercase with .lower()\n",
    "    for letter in word:\n",
    "        total_score = total_score + score_lookup[letter.lower()]\n",
    "    \n",
    "    return total_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Analysis is a process comprised of three basic steps:\n",
    "1. Identifying the text (or corpus) that you'd like to an analyze\n",
    "1. Apply the analysis to your prepared text\n",
    "1. Review the results\n",
    "\n",
    "In our very basic example of scrabble we just are interested in finding the points we would get for spelling a specific word. \n",
    "\n",
    "In a more complex example with a larger corpus you can do any of the following types of analysis:\n",
    "- determine the sentiment (positive / negative tone) of the text\n",
    "- quantify how complex a piece of writing is based on the vocabulary it uses\n",
    "- determine what topics are in your corpus\n",
    "- classify your text into different categories based on what it is about\n",
    "\n",
    "Of course, there are many other different outcomes you can get from peforming text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try questions Q1 - Q2 and type \"All Done\" in the chat box when you are done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 \n",
    "\n",
    "Score your name by creating the text variable _name_ on line 1.\n",
    "\n",
    "How many Points do you get for your name? Complete the expression below to find out the scrabble score of your name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = \"\"\n",
    "print(\"Score for my name is:\", scrabble_score(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Score your pet's name (or favorite character from a story)  by creating the text variable _pet_name_ on line 1.\n",
    "Does your name or the name of your pet score higher in Scrabble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pet_name = \"\"\n",
    "print(\"Score for my pet's name is:\",scrabble_score(pet_name))\n",
    "\n",
    "#Compare to see which gets more points!\n",
    "if scrabble_score(pet_name) > scrabble_score(name):\n",
    "    print(\"My pet's name scores more points!\")\n",
    "else:\n",
    "    print(\"My name scores more (or the same) amount of points as my pets name\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond the basics\n",
    "\n",
    "We just completed a very basic text analysis where we analyzed two different bits of text to see which one scores higher in Scrabble. Let's expand this idea to a more complex example using the [TextBlob](https://textblob.readthedocs.io/en/dev/) Python Library. There are other more complex libraries that you can use for text analysis, we are using more simple solutions so we can spend more time looking at results compared to setting up the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing and Loading the Libraries\n",
    "\n",
    "This next cell will install and load the requires libraries that will do the text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Install textblob using magic commands\n",
    "#Only needed once\n",
    "%pip install textblob\n",
    "#%python -m textblob.download_corpora\n",
    "#%pip install textblob.download_corpora\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "\n",
    "#Let's make sure our previews show more information\n",
    "pd.set_option('display.max_colwidth', 999)\n",
    "\n",
    "#Classifier for laster \n",
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "![winnie_splash](https://raw.githubusercontent.com/BrockDSL/Text_Analysis_with_Python/master/winnie_splash.png)\n",
    "\n",
    "Corpus is a fancy way of saying the text that we will be looking at. Cleaning up a corpus and getting it ready for analysis is a big part of the process, once that is done the rest is easy. For our example we are going to be looking at some entries from the 1900 [diary](https://dr.library.brocku.ca/handle/10464/7282) of Winnie Beam. The next cell will load this corpus into a Pandas dataframe and show us a few entires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "winnie_corpus = pd.read_csv('https://raw.githubusercontent.com/BrockDSL/Text_Analysis_with_Python/master/winnie_corpus.txt', header = None, delimiter=\"\\t\")\n",
    "winnie_corpus.columns = [\"page\",\"date\",\"entry\"]\n",
    "winnie_corpus['date'] = pd.to_datetime(winnie_corpus['date'])\n",
    "winnie_corpus['entry'] = winnie_corpus.entry.astype(str)\n",
    "\n",
    "#preview our top entries\n",
    "winnie_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Sentiment\n",
    "\n",
    "We can analyze the _sentiment_ of the text (more [details](https://planspace.org/20150607-textblob_sentiment/).) The next cell demonstrates this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "happy_sentence = \"Python is the best programming language ever!\"\n",
    "sad_sentence = \"Python is difficult to use, and very frustrating\"\n",
    "\n",
    "\n",
    "print(\"Sentiment of happy sentence \", TextBlob(happy_sentence).sentiment)\n",
    "print(\"Sentiment of sad sentence \", TextBlob(sad_sentence).sentiment)\n",
    "\n",
    "# polarity ranges from -1 to 1.\n",
    "# subjectvity ranges from 0 to 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "Try a couple of different sentences in the code cell below. See if you can create something that scores -1 and another that scores 1 for _polarity_. See if you can minimize the _subjectivity_ of your sentence. *Share your answers in the chat box*. \n",
    "\n",
    "(We can create a multi line string of text by putting it in triple quotes like the cell following.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "print(\"Score of test sentence is \", TextBlob(test_sentence).sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Sentiment to our Diary entries\n",
    "\n",
    "This next cell will score each diary entry in a new column that will be added to the dataframe. We loop through each entry, calculate the two scores that represent the sentiment. After all the scores are computed with add them to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Apply sentiment analysis from TextBlob\n",
    "\n",
    "polarity = []\n",
    "subjectivity = []\n",
    "\n",
    "\n",
    "for day in winnie_corpus.entry:\n",
    "    #print(day,\"\\n\")\n",
    "    score = TextBlob(day)\n",
    "    polarity.append(score.sentiment.polarity)\n",
    "    subjectivity.append(score.sentiment.subjectivity)\n",
    "    \n",
    "winnie_corpus['polarity'] = polarity\n",
    "winnie_corpus['subjectivity'] = subjectivity\n",
    "\n",
    "\n",
    "#Let's look at our new top entries\n",
    "winnie_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have daily sentiment values, let's try to visualize how they go up and down over the course of the first 3 months of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's graph out the sentiment as it changes day to day.\n",
    "\n",
    "plt.plot(winnie_corpus[\"date\"],winnie_corpus[\"polarity\"])\n",
    "plt.xticks(rotation='45')\n",
    "plt.title(\"Sentiment of Winnie's Diary Entries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting spikes?\n",
    "\n",
    "We see some really strong negative and positive spikes in the sentiment. Let's just take a look at some of those entries. Run the next three cells to look at the individual negative and positive entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of looking at just the hightest and lowest value we'll reduce that number by a threshold value\n",
    "#that way we can see numbers that are close to the highest sentiment and the lowest sentiment\n",
    "#we'll start with 20%.\n",
    "\n",
    "\n",
    "threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very Negative\n",
    "bad_sentiment = winnie_corpus[\"polarity\"].min()\n",
    "\n",
    "#Reduce this number by threshold %\n",
    "bad_sentiment = bad_sentiment - (bad_sentiment * threshold)\n",
    "\n",
    "winnie_corpus[winnie_corpus[\"polarity\"] <= bad_sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very Positive\n",
    "good_sentiment = winnie_corpus[\"polarity\"].max()\n",
    "\n",
    "#Reduce this number by threshold %\n",
    "good_sentiment = good_sentiment - (good_sentiment * threshold)\n",
    "\n",
    "winnie_corpus[winnie_corpus[\"polarity\"] >= good_sentiment]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Do you agree with the sentiment scores that are applied in the above two cells? Share your thoughts in the chat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What else can we get from the text?\n",
    "\n",
    "We've seen some details about sentiment, but what else can we get from the text? Let's grab a random entry and see what we can find out about it. We'll choose the *22*nd entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "entry_number = 22\n",
    "bit_of_corpus = TextBlob(winnie_corpus[\"entry\"][entry_number])\n",
    "bit_of_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentences and Sentiment\n",
    "\n",
    "We applied sentiment on to daily entries but we can apply it down to sentences just to see how a score fluctuates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sentence in bit_of_corpus.sentences:\n",
    "    print(sentence)\n",
    "    print(sentence.sentiment,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words in sentences\n",
    "\n",
    "You can parse through words in a sentence using TextBlob as well. The next cell illustrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sentence in bit_of_corpus.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "Another random journal entry. Pick a random number between 1 and the length of the dataframe and update *en_no* in line 1. If you get an interesting result, share it with the class in the chat box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pick a value between 1 and this number\n",
    "len(winnie_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en_no = \n",
    "\n",
    "another_bit_of_corpus = TextBlob(winnie_corpus[\"entry\"][en_no])\n",
    "\n",
    "print(\"Random Entry: \\n\")\n",
    "print(another_bit_of_corpus,\"\\n\")\n",
    "\n",
    "#Go through all of the sentences of this entry and determine their sentiment\n",
    "for sentence in another_bit_of_corpus.sentences:\n",
    "    print(sentence)\n",
    "    print(sentence.sentiment,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noun Phrases\n",
    "\n",
    "We can get a good idea about what a corpus is about by looking at the different _nouns_ that show up in it. _Nouns_ that show up a lot give us an idea of the contents of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for np in bit_of_corpus.noun_phrases:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at the corpus\n",
    "\n",
    "Let's look at the January Diary entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#January Entries\n",
    "jan_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-01-01') & (winnie_corpus['date'] <= '1900-01-31')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what Winnie talks about the most in the month. We can do this by extracting the _noun phrases_ in her entries. We can put them in a dictionary to count how many times a phrase is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jan_phrases = dict()\n",
    "\n",
    "for entry in jan_corpus.entry:\n",
    "    tb = TextBlob(entry)\n",
    "    for np in tb.noun_phrases:\n",
    "        if np in jan_phrases:\n",
    "            jan_phrases[np] += 1\n",
    "        else:\n",
    "            jan_phrases[np] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Print the top 10 things she mentioned in January\n",
    "\n",
    "for np in sorted(jan_phrases, key=jan_phrases.get, reverse=True)[0:10]:\n",
    "    print(np, jan_phrases[np])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "Let's compare against the first 6 months of the year. Run the following set of cells.\n",
    "What can you say about Winnie's topics over the first half of the year? Share your thoughts in the chat box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#February Entries\n",
    "feb_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-02-01') & (winnie_corpus['date'] <= '1900-02-28')]\n",
    "\n",
    "feb_phrases = dict()\n",
    "\n",
    "for entry in feb_corpus.entry:\n",
    "    tb = TextBlob(entry)\n",
    "    for np in tb.noun_phrases:\n",
    "        if np in feb_phrases:\n",
    "            feb_phrases[np] += 1\n",
    "        else:\n",
    "            feb_phrases[np] = 1\n",
    "            \n",
    "#Print the top 10 things she mentioned in February\n",
    "\n",
    "for np in sorted(feb_phrases, key=feb_phrases.get, reverse=True)[0:10]:\n",
    "    print(np, feb_phrases[np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#March Entries\n",
    "mar_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-03-01') & (winnie_corpus['date'] <= '1900-03-31')]\n",
    "\n",
    "\n",
    "mar_phrases = dict()\n",
    "\n",
    "for entry in mar_corpus.entry:\n",
    "    tb = TextBlob(entry)\n",
    "    for np in tb.noun_phrases:\n",
    "        if np in mar_phrases:\n",
    "            mar_phrases[np] += 1\n",
    "        else:\n",
    "            mar_phrases[np] = 1\n",
    "            \n",
    "#Print the top 10 things she mentioned in March\n",
    "\n",
    "for np in sorted(mar_phrases, key=mar_phrases.get, reverse=True)[0:10]:\n",
    "    print(np, mar_phrases[np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#April Entries\n",
    "april_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-04-01') & (winnie_corpus['date'] <= '1900-04-30')]\n",
    "\n",
    "april_phrases = dict()\n",
    "\n",
    "for entry in april_corpus.entry:\n",
    "    tb = TextBlob(entry)\n",
    "    for np in tb.noun_phrases:\n",
    "        if np in april_phrases:\n",
    "            april_phrases[np] += 1\n",
    "        else:\n",
    "            april_phrases[np] = 1\n",
    "            \n",
    "#Print the top 10 things she mentioned in April\n",
    "\n",
    "for np in sorted(april_phrases, key=april_phrases.get, reverse=True)[0:10]:\n",
    "    print(np, april_phrases[np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#May Entries\n",
    "may_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-05-01') & (winnie_corpus['date'] <= '1900-05-31')]\n",
    "\n",
    "may_phrases = dict()\n",
    "\n",
    "for entry in may_corpus.entry:\n",
    "    tb = TextBlob(entry)\n",
    "    for np in tb.noun_phrases:\n",
    "        if np in may_phrases:\n",
    "            may_phrases[np] += 1\n",
    "        else:\n",
    "            may_phrases[np] = 1\n",
    "            \n",
    "#Print the top 10 things she mentioned in may\n",
    "\n",
    "for np in sorted(may_phrases, key=may_phrases.get, reverse=True)[0:10]:\n",
    "    print(np, may_phrases[np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#June Entries\n",
    "june_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-06-01') & (winnie_corpus['date'] <= '1900-06-30')]\n",
    "\n",
    "june_phrases = dict()\n",
    "\n",
    "for entry in june_corpus.entry:\n",
    "    tb = TextBlob(entry)\n",
    "    for np in tb.noun_phrases:\n",
    "        if np in june_phrases:\n",
    "            june_phrases[np] += 1\n",
    "        else:\n",
    "            june_phrases[np] = 1\n",
    "            \n",
    "#Print the top 10 things she mentioned in june\n",
    "\n",
    "for np in sorted(june_phrases, key=june_phrases.get, reverse=True)[0:10]:\n",
    "    print(np, june_phrases[np])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7\n",
    "\n",
    "Get a piece of text and put it through some analysis. You can try to get something from:\n",
    "- [CBC news](https://www.cbc.ca/news)\n",
    "- [New York Times](https://www.nytimes.com/)\n",
    "- The text of a tweet...\n",
    "- What else?\n",
    "\n",
    "Share the text you've analyzed by sharing a link in the chat box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ex_corpus = \"\"\"\n",
    "\n",
    "**Put your text in here***\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "eTB = TextBlob(ex_corpus)\n",
    "\n",
    "#Sentiment\n",
    "print(\"Sentiment:\\n\")\n",
    "print(eTB.sentiment)\n",
    "\n",
    "\n",
    "#Noun Phrases\n",
    "print(\"\\nNoun Phrases:\\n\")\n",
    "ex_phrases = dict()\n",
    "\n",
    "for np in eTB.noun_phrases:\n",
    "    if np in ex_phrases:\n",
    "        ex_phrases[np] += 1\n",
    "    else:\n",
    "        ex_phrases[np] = 1    \n",
    "\n",
    "for np in sorted(ex_phrases, key=ex_phrases.get, reverse=True):\n",
    "    print(np, ex_phrases[np])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very basic classifier\n",
    "\n",
    "We looked at how to score the sentiment of a corpus. We can also create a classifier on our own if we provide testing and training data. In our example we are going to look at whether some statements about Twitter are subjective ( _sub_ ) or objective ( _obj_ )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = [\n",
    "    ('I think Twitter is stupid', 'sub'),\n",
    "    ('Lots of people send too much time on Twitter.', 'obj'),\n",
    "    ('Twitter is a waste of time.', 'sub'),\n",
    "    ('Twitter can be used to find information.', 'obj'),\n",
    "    ('Many celebrites have Twitter accounts.', 'obj'),\n",
    "    ('I think there is too much misinformation on Twitter', 'sub'),\n",
    "    (\"I don't like Twitter.\", 'sub'),\n",
    "    (\"Twitter is the best ever\", 'sub'),\n",
    "    ('Twitter is great because all of my friends us it', 'sub'),\n",
    "    ('Twitter is a fortune 500 company', 'obj')\n",
    "    ]\n",
    "\n",
    "\n",
    "test = [\n",
    "     ('Twitter is a company', 'obj'),\n",
    "     (\"You can't communicate well with such short sentences\", 'sub'),\n",
    "     (\"Twitter is disruptive to soceity\", 'sub'),\n",
    "     (\"Over 500 million people use Twitter\", 'obj'),\n",
    "     ('A Twitter message can have 280 characters', 'obj'),\n",
    "     (\"A Twitter message is always stupid\", 'sub')\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Builds the classifer and run the training data through it\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Classify each item in the test set to see how well the classifier works.\n",
    "\n",
    "for item in test:\n",
    "    print(\"Item: \",item[0],\"\\t\\t Classification guess: \",cl.classify(item[0]),\"\\t Actual: \",item[1])\n",
    " \n",
    "print(\"\\nAccuracy of guesses\", cl.accuracy(test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can have the classifer tells us some things it has noticed with the samples\n",
    "cl.show_informative_features(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8\n",
    "\n",
    "As our last activity try to create your own classifier in the next code cell. You'll just need to provide examples for the classifer to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_2 = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('','pos'), #add a positive sentence\n",
    "    ('','pos'), #add a positive sentence\n",
    "    ('','pos'), #add a positive sentence\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('','neg'), #add a negative sentence\n",
    "    ('','neg'), #add a negative sentence\n",
    "    ('','neg')  #add a negative sentence\n",
    "    ]\n",
    "\n",
    "\n",
    "cl_2 = NaiveBayesClassifier(train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell as often as you'd like to have the classifier attempt more sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nInput a sentence you wish to classify\")\n",
    "test_sentence = input()\n",
    "print(\"Classification category: \", cl_2.classify(test_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats!\n",
    "\n",
    "You have now learned the basics of Text Analysis using Python and TextBlob. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Links\n",
    "\n",
    "\n",
    "- [Sentiment Analysis of Tweets Using Python](https://www.greycampus.com/blog/data-science/sentiment-analysis-on-twitter-tweets-using-python) - a case study that uses twitter data to generate sentiment values.\n",
    "\n",
    "\n",
    "- [VADER](https://github.com/cjhutto/vaderSentiment#python-demo-and-code-examples) - (Valence Aware Dictionary and sEntiment Reasoner) is a sentiment library designed to be used for social media that can better reflect the sentiment of slang, emoticons and hashtags.\n",
    "\n",
    "\n",
    "- [Topic Modelling with gensim](https://towardsdatascience.com/topic-modeling-with-gensim-a5609cefccc) - The next step in your understanding of text analysis should be topic modelling, where we try to determine what topics are in a corpus. It is bit too complex to tackling in this workshop.\n",
    "\n",
    "\n",
    "- [Kaggle](https://www.kaggle.com/search?q=text+analysis) - If you do data science using a Python in a notebook, this the place for you.\n",
    "\n",
    "\n",
    "- [Python for Librarians](https://libraryjuiceacademy.com/shop/course/270-python-for-librarians/) - An upcoming workshop that will look at many interesting pieces of Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
